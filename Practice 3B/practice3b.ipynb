{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B: Practice\n",
    "In this exercise, you will practice inferential statistics with confidence intervals, bootstrapping, and hypothesis testing. Problems may involve a combination of math and code. \n",
    "\n",
    "Recall that you can use LaTeX to nicely format your math inside Markdown cells by enclosing equations in single dollar signs (e.g., $x^2+4=8$) for inline math or double dollar signs for centered equations like $$P(X > 5) = \\frac{1}{6}.$$ For a reference if you are new to LaTeX, see the [overleaf documentation for mathematical expressions](https://www.overleaf.com/learn/latex/mathematical_expressions). \n",
    "\n",
    "Show your work and/or briefly explain your answers. In general you will not receive full credit for numeric answers with no accompanying work or justification (math, code, explanation). For numeric answers, we will accept answers that are very slightly off due to rounding, z score of 2 vs. 1.96, etc. \n",
    "\n",
    "When you finish please go to Kernel --> Restart and Run All, and then double check that your notebook looks correct before submitting your .ipynb file (the notebook file) on gradescope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this code cell to import relevant libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1\n",
    "The General Social Survey asked the following question to a random sample of 1,155 Americans: “After an average work day, about how many hours do you have to relax or pursue activities that you enjoy?” A 95% confidence interval for the mean number of hours spent relaxing or pursuing activities they enjoy was (1.38, 1.92).\n",
    "\n",
    "1. Your friend reads the survey and says it means \"95% of the survey respondents reported between 1.38 and 1.92 hours.\" Is this a valid interpretation of the confidence interval? Why or why not?\n",
    "2. Suppose another set of researchers reported a confidence interval of (1.29, 2.01) based on the same sample of 1,155 Americans. Is this indicative of a higher or lower confidence level (the percentage)?\n",
    "3. Suppose next year a new survey asking the same question is conducted, and this time the sample size\n",
    "is 2,500. Assuming that the summary statistics (mean and standard deviation) are roughly the same as before, how will the new confidence interval differ from the (1.38, 1.92) computed before? Why?\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1\n",
    "manual: true\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Question 1:\n",
    "\n",
    "No,this is not a valid interpretation because a 95% confidence interval m is a range of values that you can be 95% confident contains the true mean of the population. Not 95% of people are between that interval.\n",
    "\n",
    "\n",
    "Question 2:\n",
    "\n",
    "This is indicative of a higher confidence level because the interval for the 95% confidence originally found was (1.38,1.92) which is contained inside of (1.29, 2.01). The range getting wider means we have a higher confidence.\n",
    "\n",
    "\n",
    "Question 3:\n",
    "\n",
    "The new confidence interval will be higher because the sample size is larger meaning that we can be more confident than in the one before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 2\n",
    "1. A random survey of 1,000 US adults found that 42% believe raising the minimum wage will help the economy. Using the normal distribution, construct a 95% confidence interval for the true percentage of US adults who believe this using the normal distribution.\n",
    "2. A study of 19 random Risso's dolphins finds that the average amount of micrograms of mercury per wet gram of muscle in a dolphin is 4.4, with a standard deviation of 2.3. Construct a 95% confidence interval around this empirical mean using the student's t-distribution.   \n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "manual: false\n",
    "points:\n",
    "    - 2\n",
    "    - 2\n",
    "    - 2\n",
    "    - 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6a799621bfde>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msigma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.42\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mconfidenceInterval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0malpha1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mconfidenceInterval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mconfidenceInterval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mu' is not defined"
     ]
    }
   ],
   "source": [
    "# Code for question 2 (or can use a hand calculator and show work)\n",
    "# Please store the answer for each questions as following variables\n",
    "alpha1 = 0.95\n",
    "vmu= 0.42\n",
    "sigma = np.sqrt(0.42*(1-0.42))\n",
    "n= 1000\n",
    "confidenceInterval = list(stats.norm.interval(alpha= alpha1, loc = mu, scale = sigma/np.sqrt(n)))\n",
    "confidenceInterval[0] *= 100\n",
    "confidenceInterval[1] *= 100\n",
    "\n",
    "q2_1 = confidenceInterval # 95%CI stored as a list or tuple with [lower-bound, upper-bound]\n",
    "\n",
    "\n",
    "mu = 4.4\n",
    "sigma = 2.3\n",
    "n = 19\n",
    "df1 = n-1\n",
    "confidenceInterval2 = stats.t.interval(alpha = alpha1, df = df1, loc = mu, scale = sigma/np.sqrt(n))\n",
    "\n",
    "\n",
    "q2_2 = confidenceInterval2 # 95%CI stored as a list or tuple with [lower-bound, upper-bound]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 2 Explanation\n",
    "\n",
    "For the first part. The mean was 0.42, confidence interval as 0.95, sigma was calculated using the square root of the mean times 1 minus the mean. Then when put into scale it is divided by the square root of n=1000. A normal distribution was used.\n",
    "\n",
    "For the second part. The mean was 4.4, confidence interval as 0.95, sigma was calculated using the square root of the mean\n",
    "times 1 minus the mean. Then when put into scale it is divided by the square root of n=19. A t-distribution was used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "### Question 3\n",
    "You have a small dataset of the total number of miles that a random subset of individuals have walked over the last week: `data = [1, 3, 4, 8, 14, 23, 39, 51, 106, 319]` as defined in the code below.\n",
    "1. Construct a 95% confidence interval for the mean of `data` using the student's t-distribution.\n",
    "2. Use bootstrapping with 100,000 bootstrap resamples to construct a 95% confidence interval for the mean of `data`.\n",
    "3. Which confidence interval is more reasonable? Why?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3\n",
    "manual: false\n",
    "points:\n",
    "    - 2\n",
    "    - 2\n",
    "    - 2\n",
    "    - 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run but do not modify\n",
    "data = np.array([1, 3, 4, 8, 14, 23, 39, 51, 106, 319])\n",
    "\n",
    "# Code for question 3\n",
    "# Please store the answer for each questions as following variables\n",
    "# Store the answer as a list or tuple with [lower-bound, upper-bound]\n",
    "alpha1 = 0.95\n",
    "mu = np.mean(data)\n",
    "sigma = np.std(data)\n",
    "n = len(data)\n",
    "df1 = n-1\n",
    "\n",
    "confidenceInterval3 = stats.t.interval(alpha = alpha1, df = df1, loc = mu, scale = sigma/np.sqrt(n))\n",
    "\n",
    "q3_1 = confidenceInterval3 # 95% CI using t-distribution\n",
    "\n",
    "bootstraps = 100000\n",
    "bootstrap_resample = np.random.choice(data, size = (bootstraps, n), replace = True)\n",
    "means = np.average(bootstrap_resample, axis =1)\n",
    "bootstrapConfIntlower = np.percentile(means, 2.5)\n",
    "bootstrapConfIntupper = np.percentile(means, 97.5)\n",
    "\n",
    "\n",
    "q3_2 = [bootstrapConfIntlower,bootstrapConfIntupper]# 95% CI with bootstrapping\n",
    "print(q3_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Q 3.3\n",
    "The bootstrapping is more realistic because of what we are measuring. Walking negative miles doesn't make sense and the t-distribution has negative while bootstrapping has only positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 4\n",
    "#### Part 1. \n",
    "It is believed that nearsightedness affects about 8% of all children. In a random sample of 194 children, 21 are nearsighted. Consider the following question: do these data provide evidence that the 8% value is inaccurate? State the specific hypotheses you will test to answer this question and indicate whether it is a one-sided or two-sided test (you can do either, just clarify which). Use a significance level of 0.05. Conduct the hypothesis test and calculate the p-value using the normal distribution. Interpret your result.\n",
    "\n",
    "#### Part 2.\n",
    "A USA Today/Gallup poll asked a group of unemployed and underemployed Americans if they have had major problems in their relationships with their spouse or another close family member as a result of not having a job (if unemployed) or not having a full-time job (if underemployed). 27% of the 1,145 unemployed respondents and 25% of the 675 underemployed respondents said they had major problems in relationships as a result of their employment status. Consider the following question: is the percentage of those having major problems different for unemployed versus underemployed Americans? State the specific hypotheses you will test to answer this question and indicate whether it is a one-sided or two-sided test (you can do either, just clarify which). \n",
    "\n",
    "Use a significance level of 0.05. Conduct the hypothesis test and calculate the p-value. You can do so most easily using [`scipy.stats.ttest_ind_from_stats`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind_from_stats.html#scipy.stats.ttest_ind_from_stats), though you can also look up the standard error calculations for the difference of proportions in Chapter 6.2 of the openIntro Statistics book referenced in the Prepare if you wish to run the test using the normal distribution for a (very) slightly tighter p-value (you will get similar p-values and the same conclusion either way). Interpret your result.\n",
    "\n",
    "\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "manual: False\n",
    "points:\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "    - 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for question 4\n",
    "# Please store the answer for each questions as following variables\n",
    "sigma = np.sqrt(0.08*(1-0.08))\n",
    "value = (21/194-0.08)/sigma * np.sqrt(194)\n",
    "calculatedProbability = 2*(1-stats.norm.cdf(value))\n",
    "\n",
    "q4_1 = calculatedProbability # part 1: P_value\n",
    "\n",
    "\n",
    "firstSigma = np.sqrt(0.27*(1-0.27))\n",
    "secondSigma = np.sqrt(0.25*(1-0.25))\n",
    "result = stats.ttest_ind_from_stats(mean1 = 0.27, std1=firstSigma, nobs1 = 1145,\n",
    "                                   mean2 = 0.25, std2 = secondSigma, nobs2= 675)\n",
    "finalresult = list(result)[1]\n",
    "\n",
    "q4_2 = finalresult # part 2: P_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 4 Interpretation\n",
    "\n",
    "Part 1:\n",
    "When looking at the question I identified the different hypothesis. The alternative hypothesis was that it is inaccurate to say 8% of children are affected by nearsightedness. And the null hypothesis is that 8% of children are affected by nearsightedness.\n",
    "I used the function for a normal distribution to find the p-value of 0.14699. However, the significance level was 0.05 which is lower than the p-value so we cannot reject the null hypothesis.\n",
    "\n",
    "Part 2:\n",
    "For this question as well there are difference hypothesis. The alternative hypothesis was if the percentages are different for the major problems of unemployed and underemployed americans. And the null hypothesis is that it is the same percentage for both. I used the function for a T-test to calculate a p-value of 0.3489695. However, the significance level is 0.05 which is lower than the p-value so we cannot reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 5\n",
    "Below we import two data sets `university_data` both with and without NAs in the `cost_after_aid` column. The first dataset contains information about 311 universities in the United States. In general, private universities charge higher tuition rates than public universities. However, private universities often argue that once you take financial aid into account, the cost is often not different. In this question you will explore this issue.\n",
    "\n",
    "1. First, report the average `tuition` of `public` schools and the average `tuition` of `private` schools to confirm the basic notion that `private` schools charge higher tuition on average.\n",
    "\n",
    "2. Consider the null hypothesis that `private` and `public` universities have the same average `cost_after_aid`. Conduct a two-sided t-test to determine whether the dataset provides statistically significant evidence to reject the null hypothesis in favor of the alternative hypothesis that they have different average `cost_after_aid`. You will notice that some universities do not have a value recorded for `cost_after_aid`. For now, use `uni_caa_no_na` instead for your analysis and assume that the remaining are a random sample of American universities. Report the resulting p-value. Interpret your results at a significance level of 0.05.\n",
    "\n",
    "3. In the previous step you tested for statistical significance of the difference in `cost_after_aid` between public and private schools. What is the effect size? Report the average `cost_after_aid` of `public` schools and the average `cost_after_aid` of `private` schools.\n",
    "\n",
    "4. In step 2 we assumed that we could omit the universities with missing data and the remainder would be a random sample of American universities. Is that assumption well justified? Consider especially the average values you computed in steps 1 and 3 and consider which universities are missing the `cost_after_aid` information. Given this, what can you say about the claim that \"private universities often argue that once you take financial aid into account, the cost is often not different?\"\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5_auto\n",
    "manual: false\n",
    "points:\n",
    "    - 2\n",
    "    - 2\n",
    "    - 1\n",
    "    - 1\n",
    "    - 2\n",
    "    - 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run but do not modify this code\n",
    "uni = pd.read_csv(\"university_data.csv\")\n",
    "uni_caa_no_na = pd.read_csv(\"university_data_caa_no_na.csv\")\n",
    "uni.head()\n",
    "\n",
    "# Code for question 5 here\n",
    "# Place your answer in a list in following orders\n",
    "\n",
    "publicSchool = np.mean(uni[uni[\"institution_type\"] == \"public\"][\"tuition\"])\n",
    "privateSchool = np.mean(uni[uni[\"institution_type\"] == \"private\"][\"tuition\"])\n",
    "\n",
    "q5_1 = [publicSchool,privateSchool] # [public, private]\n",
    "\n",
    "publicCostAfterAid = uni_caa_no_na[uni_caa_no_na[\"institution_type\"] == \"public\"][\"cost_after_aid\"]\n",
    "privateCostAfterAid = uni_caa_no_na[uni_caa_no_na[\"institution_type\"] == \"private\"][\"cost_after_aid\"]\n",
    "\n",
    "result = stats.ttest_ind_from_stats(mean1 = np.mean(publicCostAfterAid), std1=np.std(publicCostAfterAid), nobs1 = len(publicCostAfterAid),\n",
    "                                   mean2 = np.mean(privateCostAfterAid), std2=np.std(privateCostAfterAid), nobs2= len(privateCostAfterAid))\n",
    "\n",
    "q5_2 = list(result)[1]# p-value\n",
    "\n",
    "\n",
    "meanPublic = publicCostAfterAid.mean()\n",
    "meanPrivate = privateCostAfterAid.mean()\n",
    "effect_size = meanPublic-meanPrivate\n",
    "q5_3 = [meanPublic,meanPrivate,effect_size] # [public, private, effect_size], notes: the effect size should be positve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Question 5.4\n",
    "\n",
    "No that assumption is not well justified because of the differences in percentages with schools with missing data. There is a general higher percentage of schools that are public with missing data. This missing data of schools have a lower cost and can edit the results. Therefore the final claim that the cost is no different cannot be proven."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
